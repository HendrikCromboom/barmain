# barmAIn
# Introduction

 Demonstration of an LLM integration within MCP.
 Will run headless within what most likely will be a Django user interface, in the MVP the query is hardcoded and the output is terminal based.
 Instructions will be added down the road.
 An UI will be added down the road.
 The entire project will set up something regarding a bartending, cocktail making app integrating AI. All wrapped withing detacheable Agents and components.
 I will probably start out using the IO protocol and see if I find the time to run it seperate with streams.
 

 ## Resources

 - MCP Python SDK
 - Langchain
 - Langchain Llama
 - Ollama

 ## Goal

 The goal is mostly to show of a manageable project that uses some software that I have been getting experience with in a personal project I am not yet willing to publish without a license.
 My proficiency with skills I want to mainly highlight are:
 - MCP(Not just a client, but the setup of an entire ecosystem)
 - Python(See above)
 - LLMs

 ## Objects and Requests(Basic)

TBD
